Stats744: Data Visualization


Sep 9, 2019
How Humans See Data: John Rauser video:
https://www.youtube.com/watch?v=fSgEeI2Xpdc

	-way easier for ppl to know what is going on when you visualize it
	-users dont even need to think about what they are looking at
	-tables are bad
	-what TYPE of visualization you use is important!
	-3 visual operations of pattern preception (how humans decode a graph):
		1. Detection:recognizing that a geometric object encodes a value
		2. Assembly: grouping of detected elements (^)
		3. Estimation: visual assessment of relative magnitude of 2 or more quantative values
	-Estimation:
		-3 levels of estimation:
			a. discrimination (two things are or are not the same)
			b. ranking (one is bigger or smaller)
			c. ratioing (can tell what ratio btwn 2 values is)
		-efficent comparison of values visually
		-so we want to do a-b above as efficently and accuratly as possible
		-7 most important things when presenting data from most effective to least effective:
			-Position along a common scale 
			-Positin on identical but nonaligned scales
			-Length
			-Angle or Slope
			-Area
			-Volume or density or colour saturation
			-Colur hue
		-so you think about what you want to show and try to show it using top stuff first then go to the bottom, the more comparisons you want to make the more of this you will have to include
		-so if you want to compare 2 values, you should physically out them beside eachother on the graph or table or whatever
		-the farther they are apart the harder it is for us to see if they are different or not
		-if ppl need to refer to your legend to remember what colour is what then it will take them longer to get the info you want them to because it is a "table look-up"
		-alphabetical is almost NEVER good! we hardle see things like that IRL and therefore its harder for us to get
		-saturation is easier for ppl to discriminate over hue. so going from light to dark of the SAME colour is easier and provides a natural ordering. where as hue does not
		-ratioing is easier with saturation than hue, bc we are better at estimating it than comparing btwn colours
		-area means making something x times bigger in the physical size of the circle if it actually is x times bigger in value. here it is super easy to do ratio
		-area is only good if zero value means it would be zero in size. and we are changing the area not the radius!
		-length is used all the time when we are looking at errorbars
		-position on identical but not aligned scales would be 2 graphs side by side with the same x-axis scale but different y axis
		-NEVER USE STACKED BAR GRAPHS
		-hue is good for categorical data!! v effective
		-parallel coordinates chart is better than stacked
		-so if you want total infor but also how many of each in each category then you should just have 2 charts side by side to show that instead of trying to cram it all into one graph.
		-and this is bc stacking makes us decode length which is way down the list compared to position on a common scale which we are really good at
		-pie charts suck.
		-comparison is super easy on a common scale
		-so insetad of having 2 graphs with the same x-axis but different y axis you can just plot them on the same graph, by standardizing the series so they are now on the same "scale"
		-there are always trade offs bc then you lose information liek the absoloute value of the data but still can be more effective. so always think about what you are trying to show and how you do that most effectively
		-scatter plot shows things the best!
		-we can easily see how 2 things are reltated to eachother to see if they both go up together or not
		-so whatever is most important you should plot it directly so that you get the most effective graph
		-humans are super good at taking meaningless shapes and filling in the blanks and making a full picture even if its not necessarally there
		-we will group together objects that go in a similar direction, which makes it easy for us to get the point of the graph
		-so how we order data (not alphebitcal but maybe by magnitude) is super important bc we can often fill in the blanks of what the trends should be
		-tend to see elements that are physically similar as part of the same group
		-shape and colour are good ways to do this
		-redundancy is good so do different shapes and colour and maybe even put like error bar tubes around the data to further segment it into your categories
		-dodged bar charts are often a bad idea
		-lines for a grid sometimes are distracting! so make them muted!
		-important to have the points be sufficently luminant from the background (so contrast) so they are easy to see)
		-so grid lines are sometimes usefull bc we are better at detecting differences btwn small numbers than big differences. so when the difference looks big bc the size of the bars or numbers is small we are better at it than when the bars are big.
		-so grid lines can be good bc they put that "JUST noticable" difference into a frame and then we can easily see it and compare
		-we can best detect slope when it is near 45deg so bank your slopes to be close to that so ppl can tell better, so log scale or whatever
		-change axis so average slope is 45deg




Data Visualization Book:
https://serialmentor.com/dataviz/

	Coordinate systems and axes:
		-tall and narrow figs emphasize change on the y axis
		-short and wide figs emphasize change on the x axis
		-if change is equal on x and y then they spacing and aspect ratio should be equal
		-when using log transformed data, always specify the base in the axis label
		-when doing a ratio (so like number divided by mean) it should always be on a log scale so you can actually see the differences. otherwise it is too squished.
		-square root scale allows for the presence of 0 where as a log scale cant
		-appropriate scaling should be used to make the point of the figure more obvious. so if it should be drastically decreasing, make the scale so the bars look like they are drastically decreasing.
		-polar coords is good when you are dealing with cyclical data or periodic data. bc then your first and last points will be close together

	Colour:
		-colour can be used to hilight, distinguish groups of data, or represent data values
		-depending on what you want to show, sometimes you dont want your colours to be ordered otherwise it may imply an order in the data, and you want distinct colours if you are showing distinct data (so not continuous unless you can have continus values in the data)
		-so you can have your data, like a bar chart for example ordered and then have diff colours that will show another trend you want to hilight like regions on a map. (ex Fig 4.2)
		-colour hue is what we use when we want to say one value is > another or how distant 2 particular values are from a range
		-hue can be same col or different, but it has to look "natural" sunrise...etc
		-diverging col scale is when the ligthest colours are in the middle and we want to hilight the 2 extremes
		-can use light and dark versions of the colours to hilight certain bars or points in the data (baseline cols need to be drab!)

	Visualizing Amounts:
		- bar graphs are most popular
		- if your lables are too long, swap x and y axis for a pretty pic
		-ALPHABETICAL IS ALMOST NEVER GOOD (pick a meaningful order)
		- whatever you care more about (if you are dealing with multiple catories/factors, then that should be the grouping on the x axis (so in fig 6.8 we care more about wages as it varies with race, so we make age bars within each race then its easy to see black makes less)
		- facet is usually better than diff coloured bars
		- again, if our values do not contain zero, the adjust your scale so that you can see the variation in the data better
	
	Visualizing Distributions:
		- when making a histogram always explore bin widths to make sure you get one that shows the trend the best (not too big, not too small, just right)
		- kernal density graphs create area under the curve tryp graphs and work well for large datasets
		- always keep in mind the biology and if it makes sense for you to have negative data...etc
		- when showing how things range over 2 categories and they add up (like M anf F passengers = total passengers) you can plot the two side by side but have the total number as a "third" group (Fig 7.9 is really nice!)
		- for several distributions, kernal density plots are better than histograms
		- q-q plot is good bc we dont have to choose parameters like bin width and such like in histograms
		- cumulitive distribution is good. so you rank the data and then plot the ranks, ie lowest score has the lowest rank and then we can see if it tapers at one end or if there is a spike
		- its then super easy to see 25% of the students got this grade...etc
		- if we have suer skewed data we can use power law distribution to see the tails better
		- to check this you plot the decending cumulative distribution on a log scale (should see a straight line if it follows a power log)
		- we use qq plots if we want to see how well a certain dataset follow a certain distrubution
		- when they fall right on the straight line then we can assume that it follows the distribution
	
	Visualizing Many Distributions:
		- we often want to think about our data in terms of response variable and groupings. where one is on one axis and the other is on the other axis
		- ie temp is the response and would be on one axis and then the weather patterns or states would be the groupings, so we want to see how temp changes across the groupings
		- STANDARD ERROR = how acurate our estimate of the mean (or median or whatever) is 
		- STANDARD DEVIATION = how much spread there is in the data around the mean (or median or whatever)
		- with violin plots you need to make sure that you have enough data points so that you can justify making a smooth line out of the data
		- violin plots are good for determining if you have bimodal data or whatever, also have to be careful bc the violin plot can imply that there are points when really they are super sparse and the plot is just trying to make a straight line
		- sina plot is when you have a violin plot with the dots on top
		- with ridge line plots you want to have your groups on the yaxis and then the response variable on the x-axis
		- with the violin plot and the ridge line plot, the point is not to show exact density but to make it easier to compair the distributions across the groups
		- can also make the ridgeline plots into histograms, but its ugly
		- ridgeline is good when you have like 100 items in your groupings
		- ridgeline is good if you want to show two trends over time too
	
	Visualizing Proportions:
		- always pick a dataset that hilights what YOU want to show
		- can do proportions as side by side but then its hard to see how much they are represented in the total
		- nice table of when you should use pie, stacked bar or bar!
		- stacked bar it makes it hard to compare across groups (the colours in the bar) bc they are stacked
		- so then side by side bars are better
		- if you only have 2 categories of groups or colours, then stacked bars works great! super easy to see the trend
		- can then also add a reference line like 50% to show when the two groups are equal or who is more than the other
		- can use stacked densitys if you want to see how proportions change in response to a continuous variable (uses kernal density usually)
		- ex: health status of ppl as a function of age, can see that overall health decreases with age
		- but this has a limitation bc it can seem like one group has less or more than the others
		- so to fix all this you can do stacked densities, or rather densitys ontop of eachother and separating the data into chunks, say by year or month or something (there is a really good example in Ch 10)
		- can then also change this to be a proportion so that you can see how much of the total each group represents
	
	Visualizing Nested Proportions:
		- this is when you data is broken down into multple sub categories, like state, age, weight..etc
		- wrong to use pie charts when sometimes not all groups are represented across the data
		- hard to see overlap when you are dealing with proportions in a pie or bar graph
		- for these cases a mosaic plot is best bc it shows how the categories are related (really nice example in ch 11)
		- mosaic plots have different points of emphasis depending on what you want to show
		- again, comparison across groups is hard to see with mosaic plots
		- nested pie charts are possible but...ugly
		- so if you have to do a pie chart you should do a temporal gouping in a colour, and then another grouping (like building material) in hues of that colour, that way you can see that it is nested and you get an accurate representation of the data, it is clearer, but still not great in my opinion
		- can also use a tree map, but again, I think is is confusing if it is not in a phylogenetic context, also called a paralled sets plot (looks like  tree)
		- again, it is important to play up cultural norms, like reading from left to right and colour patterns...etc, can easly turn an ugly graph into a good one
	
	Visualizing Associations Among 2 or more quantative variables:
		-quantative variables like height, weight...etc
		-may be interested in how they are related to eachother
		-based on how many dimensions of these we have, we might want to pick different charts to show this
		-simple scatter plot of 2 of these with one on the x and one on the y. when we say this we say we are plotting y against x
		-can then colour the dots by categorical variables like sex or treatment, and this could give insight into how this catgorical variable may be influencing things, like all the male birds tend to be bigger..etc
		-can use a bubble chart to show a third dimension of our quantative variables by letting the dots be different based on categories of one of the quantative variables, so you will have bubbles of different size but still will be showing how 2 other quantative variable are related to eachother (x and y)
		-but bubble charts are hard to distinguish btwn the bubble charts sometimes bc it is hard to see that some bubbles are larger than others (going back to fundamental principals)
		-so an alternative is making an all-v-all matrix of scatter plots, where you compair all your quantative variables to eachother, then it is a bit easier to see how M/F or Treatment or other categorical variables are maybe separated or not in each of those variables
		Correllelogram:
			- this is for when you have more than 3-4 quantatative variables, and an all-v-all matrix will just not work
			- can calculated correlation coefficents which range from -1 to 1 and then we can see if they are correlated (positive) or anticorrelated (negative)
			- really nice pic to show how different values of coefs look
			- really nice overview on what the formula for the coefs mean and how to interpret it
			- can then make a correllologram that I think looks kind of like a heat map, with all the info about the strong correltaiton or not in both + and - directions
			- super nice way to show like 20+ correlations all at once
			- can even further improve this by making bubbles to show that the |bigger| correlations are bigger and ones near zero are smaller, makes it visually easier to see the trends
			- remember that these graphs are abstract and it is always better to visualize raw data if we can!
		Dimension Reduction:
			- PCA is useful when we are trying to reduce dimensions
			- PCA basically makes the mean and variance zero and puts the data in a linear combo
			- when you do a PCA you are usually interested in 2 things:
				1) the composition of the PCs
				2) how individual datapoints are arranged in the principal component space
			- it is usually useful to put arrows attached to each of your variables to see how much they are contributing to the PCs (I find this WAY better than the clustering PCA plot!)
			- lines that are almost vertical or horizontal are mostly contributing to the PC that is on that axis. and not the other
			- length of the arrow indicates how much it contributes to those PCs you are looking at. so shorter arrow for PC1 v PC2 would mean that that variable is contributing more to higher order PCs
			- good ex of how you would interpret the PCAs when they are clustered on the graph
		
		Paired Data:
			- talking about measuring the same variable over diff times, or lengths of a person right and left arm
			- same quantity, slightly different conditions
			- and we can therefore assume that the pairs will be more similar than the value between pairs
			- scatter plot with a line is one way to show this bc you can see if pts are close or far from the line then the pairs are similar, if not then pairs are not similar. make sure you are plotting the one condition value on one axis and the other condition value on the other axis
			- if we have a small number of comparisons, then we could do a slopegraph, where each condition is a vertical lines of the points and we connect the points to get a slope change btwn the conditions
			- this is good when we have > 2 conditions
	
	Visualizing time series and other functions of independent variable:
		-time imposes additional structure to the data that is important to think about
		- bc it gives them inherant order
		- line graphs excentuate the order of time bc you follow the points and see that each point has a left and right neighbour so a perdecessor and a future generation
		- some say that the lines are misleading bc it does not represent actual data points, so you should mention in your fig, "lines are meant as a guide to the eye"
		- no dots = emphasis on overall trend
		- colouring in the area is also fine, as long as area actually means area (counts)
		- with multiple time series over differen say doses, you need to be careful bc it can get busy
		- so point an line is helpful 
		- can also use line plots whenever the data has a natural order, low fertalizer to high...etc
		- make sure that the order is always on the x-axis
		- sometimes we have more than one response over the same time period, in this case you can put the graphs ontop of eachother to show patters over time in both the responses
		- can also plot the two variables against eachother in a connected scatter plot
		- also called a phase portrate
		- it shows how things line up for different phases and when they are "in synch" or "out of synch"
		- if you do this you NEED to indicate direction and temporal scale so that ppl can tell what the heck is going on. so making the line go from light to dark or something is helpful way to draw the viewers eye around the line
		- or you can draw arrows on the path
		- readers are more likely to confuse order and direction in a connected scatter plot than in line graphs (probs bc of cultural things that we are just not used to seeing it)
		- an easier way to use connected scatter graphs is if you reduce the dimensions first, so plotting the same thing on PC graph will make the trend more clear and you can then colour coat to show which section sof the cycle viewers are looking at
		- but again, then you are relying on interpretation of the PCs to help explain what is going on
	
	Visualizing trends:
		- we can do this by smoothing the data (by say calculating a moving average) or we can fit a cure/model

		Smoothing:
		- so most of the time we have smaller fluctuations in our trend that we almost want to blur out and focus on the big picture overarching trends
		- can use a sliding window to calculate averages and plot those for various windiw sizes
		- usually its better to use the center of the window to calculate the average so that you do not have a lag in time, could also calculate the average at the end of the window but then you will get a bigger lag
		- regardless, it is easier to point out the trend
		- limitations: gaps bc of window creating lag, might not be that smooth, have to pick the right window size
		- stats has developed curves that weight the points closer to the center of the window more so that it removes a lot of bumps in the line! brilliant!
		- called locally estimated scatterplot smoothing (LOESS)
		- so this is basically fitting low degree polynomials within each window so that the data is extra smoothed and weighted
		- these again can be tuned by adjusting parameters
		- LOESS's can be applied to things other than time series!
		- these are often nice bc they "look nice to the human eye", so it is easier to believe and interpret
		- spline is another thing you can use, highly flexible but always looks smooth
		- haha and choice of spline can REALLY change you data! so be careful!
		- *** be carfeful when interpreting results from a smooth! same data can be smoothed in different ways! **
		- probs best to do some stats test to make sure the trend you see is real and then do a smooth
		
		Modeling:
		- preferable to fit a curve compared to just smoothing, bc with that you have CIs and can make more valid interpretations
		- if we need to guess what model to fit, we can always plot multiple on the same graph and then assess
		- can also change the axis to log and then fit stuff to see how that looks, and in the example (fig 14.9) we see that the linear fit "fits" the data much better than the exponential fit (had to put this on the log scale so we could see both linear and exp as lines and then assess)
		- so avoid exp and use linear fits on log scale!!
		- better to fit a straight line to transformed data adn to fir a nonlinear curv to untransformed data
		- commonly called log-linear
		- or can also do log-log
		- basically its easier for us to look at lines than curves, so play up to this and transform your data
		
		Detrending and time-series decomposition
		- can also use detrending to hilight specific deviations
		- so if over many categories they are all subject to the same trend, like housing prices increase over time with inflation, or sunflowers get taller with age, we can then divide the data by the increases over each category to make the whole graph horizontal, then it is way easier to see how other things like a recession can cause housing booms and busts
		- point of this section is to deal with noise that can cause the trend to fluctuate, unqual external events (ie distinct housing bubbles), or cyclical variations (ie gets cold at night and hottest during mid day...almost always)
		- can smooth these fluctuations by another smoothign thing called seasonal decomposition of time series by LOESS, but there are other methods that do the same thing
		- helps us see the long term trend that we could miss when there are fluctuations bc of noise, cycles, or other external factors acting on all data pts
		- can also plot the remainder, which is difference btwn actual and smoothed average (or whatever) to help show how you got the data

	Visualizing geospatial data:
		Projections:
		- when we need to put the spear that is the earth onto a 2D map, we have to make some decisions about how we project this, which can impact how things look
		- projection can preserve angles or areas, but not both. so we much choose
		- conformal conserves shapes and angles, but not area, and causes distortions in area, espically near the poles
		- if you need to accuratly represent area, then consider the goode homolosine projection, on a global scale
		- most common map we see of the US + alaska and hawaii is often bad bc alaska is often scaled down and hawaii is often scaled up so area is NOT conserved.
		 - so we should move alaska and hawaii without changing their scales so that the fig is not misleasing
		 - we can often split the maps up into layers to hilight differen things, roads, hills, terraine
		 - it is imporatant to use a compas or scales to clearly show what you are showing
		 - scale bar is important! and choosing which layer is dependent on what you want to show and if that is adding anything or making it more distracting
		 - we can therefore also apply the pretty plot properties to maps, and plot points in the region and group them by colours based on other variables
		 - choropleth maps use colour to show densities of a variable
		 - again, choose colours to hilight what you want to hilight
		 - light coloured backgroud usually works better, so put what you want to hilight in dark
		 - we are not very good at taking a colour and matching it against a continuous scale. so binning the data is often better
		 - 4-6 bins is usually good!
		 - often better to split up the states into regions and plot your data bc if something is larder it can me misleasing to say that the WHOLE state has the value, when really its only certain regions of that state that have the value (figs 15.13 and 15.14)
		 - cartogram is used when the area can be misleading bc you could have one state take up a lot of room, but be really sparsly populated
		 - it basically deforms the area so that we can see which ones are bigger or smaller based on the actual value
		 - oooo really nice way to solve the area issue, you can make them all the same size and into little squares and the colour them by mean, that way it is not misleading that larger states draw you eye and mean they are more important
		 - can use the same concept but instead of coloured squares, make them into graphs! (cool fig 15.17)
		 - easy to see here that neighbouring states have similar patterns
	
	Visualizing uncertainty:
		- error bars and confidence bands are most popular
		- error bars are good for showing uncertanty of many different parameter estimates in a single graph
		- usually tradeoff btwn accuracy and less busy visual display
		- showing probability as a dot and a line does not help us see how it can be translated to a tangable thing
		- can use the number of coloured in squares to show what the chances of seeing something are (really nice fig 16.1)
		- this makes it clear which gives us the best chances
		- this is called frequency framing
		- but this is only good if we have binary outcome (coin toss)
		- humans are better at preceiving, counting and jusging relative frequencies of discrete objects (as long as they are not too large) then judging the relative sizes of different areas. so the counting the number of squares is more effective
		- we can combine the accuracy of the distrubution with putting areas of circles to fill in the area under the curve, then we are counting and can distinguish things better
		- better to use a small number of dots so we can calculate
		- often it is worth while to trade precision for human perception
		- this is especially important when talking to lay audience
		- mostly with stats we are taking a subset of the total data and trying to make inferences about all of it, we do this by estimation
		- standard deviation = how our points vary (actual data)
		- standard error = how our estimate varies (so mean, or model fit...etc), how well did we do with our estimate
		- depending on how you are defining your bars, can really change how things look and can mess up what you are trying to show, potentially
		- always specify what your error bars represent so that you are not confusing ppl
		- really nice graph kind of showing when you would use the different bars fig 16.6
		- so data can have similar distribution, but if you have fewer data pts then you SE bars will really vary btwn your samples
		- graded error bars are when you show the multiple CIs on the same point, so the viewer can tell that there are a range of possibilities
		- often we struggle with ppl thinking that the range of the estimate or data stops at the error bars, which is wrong, so minimizing this deterministic construal errors is importnat
		- again, to show sig, you calculate the CIs and if they DO NOT include zero (can be + or -) then they are sig
		- 16.9 fig is really nice to show the different ways you can show sig with different looking error bars to show whatever point you want
		- baysian credible interval tells us where the true parameter likely is not
		- bayesian deals with the true parameter value and if that is right, where as frequentist is about rejecting a null
		- bayesian = thinking about magnitude of effect
		- frequentist = if the effect exists or not
		- also show ways to show the credible interval

		Visualizing undertanty of curve fits:
		- confidence bands around straight line estimates of trends are curved bc we are basically fitting a bunch of tiny lines and then just plotting the area btween all of them (fig 16.16 is nice)
		- again, we can draw multiple confidence bands on one graph to show how it variessd depending on what level you choose
		- can also do this for non-linear curves
		
		Hypothetical outcome plot:
		- make a moving pic and cycle through multiple plots of different, but equally likely scenarios
		- so you basically pic a random sample that would give you a hypothetical outcome, and do this a few times and then we can hopefully see a trend
		- so in this case if we randomly piced Canada v US chocolate, 53% of the time the Canada ones would taste better, and we see this in the annimation that usually canada is larger than US about 1/2 the time
		- good for oral presentations when you can have a moving pic, less effective as a searies of plots
		- super cool with cycling through trendlines to show the different lines that would make up a CI band
		- choosing to gradually show your change or do a hard switch is preference 
		- but when you do this, you need to make sure that your representatives are true of the distribution and not an artifact of sampling.
		- so you either sample a lot, or say that some are misleading, or just state the probability at the end

